import requests
from bs4 import BeautifulSoup
import urllib3
import re
from datetime import datetime
from requests.packages.urllib3.exceptions import InsecureRequestWarning
import logging

# Enable debug-level logging
logging.basicConfig(level=logging.DEBUG)
# ç¦ç”¨ä¸å®‰å…¨è¯·æ±‚è­¦å‘Š
requests.packages.urllib3.disable_warnings(InsecureRequestWarning)
proxies = {
    "http": "14.199.30.127:80",

}                                           
def extract_links(url):
    # å‘é€HTTPè¯·æ±‚
    response = requests.get(url, proxies=proxies)
    # ç¡®ä¿è¯·æ±‚æˆåŠŸ
    if response.status_code == 200:
        # ä½¿ç”¨BeautifulSoupè§£æHTMLå†…å®¹
        soup = BeautifulSoup(response.text, 'html.parser')
        # æ‰¾åˆ°æ‰€æœ‰çš„<a>æ ‡ç­¾
        links = soup.find_all(class_="title ceo-h4")
        # æå–hrefå±æ€§
        extracted_links = [link.get('href') for link in links if link.get('href') is not None]
        return extracted_links
    else:
        return "Failed to retrieve the webpage"
def extract_links_url(url):
    # å‘é€HTTPè¯·æ±‚
    response = requests.get(url, proxies=proxies)
    # ç¡®ä¿è¯·æ±‚æˆåŠŸ
    if response.status_code == 200:
        # ä½¿ç”¨BeautifulSoupè§£æHTMLå†…å®¹
        soup = BeautifulSoup(response.text, 'html.parser')
        # æ‰¾åˆ°æ‰€æœ‰çš„<a>æ ‡ç­¾
        links = soup.find_all('a', href=lambda href: href and href.endswith('.yaml'))
        # æå–hrefå±æ€§
        extracted_links = [link.get('href') for link in links if link.get('href') is not None]
        return extracted_links
    else:
        return "Failed to retrieve the webpage"


def main():
    file1 = open("./sub/clash_online.yaml", "w+",encoding='utf-8')
    # è·å–å½“å‰æ—¥æœŸ
    current_date = datetime.now()

    url = "http://www.85la.com/internet-access/free-network-nodes"
    links = extract_links(url)
    a=extract_links_url(links[0])
    file1.write(download_content(f'{a[0]}'))
    file1.close()
    print("ok url")

def download_content(url):
    """
    ç¬¬ä¸€ä¸ªå‡½æ•°ï¼Œç”¨æ¥ä¸‹è½½ç½‘é¡µï¼Œè¿”å›ç½‘é¡µå†…å®¹
    å‚æ•° url ä»£è¡¨æ‰€è¦ä¸‹è½½çš„ç½‘é¡µç½‘å€ã€‚
    æ•´ä½“ä»£ç å’Œä¹‹å‰ç±»ä¼¼
    """
    response = requests.get(url)
    response.encoding = 'utf-8' 
    #print(response)
    text=response.text.replace('( https://www.fuye.fun/ å…è´¹èŠ‚ç‚¹åˆ†äº«)','').replace('ğŸ‘‰www.85la.com','').replace('()','').replace('( https://www.fuye.fun/å…è´¹èŠ‚ç‚¹åˆ†äº«)','')
    return text

if __name__ == '__main__':
    main()
