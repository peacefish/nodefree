import requests
import re
import yaml
from bs4 import BeautifulSoup
from datetime import datetime
def get_index_url(url):
  headers = {
      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36',
      'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
      # å…¶ä»–è¯·æ±‚å¤´å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ 
  }

  # å‘èµ· GET è¯·æ±‚
  ymal_urls = []
  try:
      response = requests.get(url, headers=headers, verify=False)  # ç¦ç”¨ SSL éªŒè¯
      #print(f"çŠ¶æ€ç : {response.text}")

      if response.status_code == 200:
        soup = BeautifulSoup(response.text, 'html.parser')
        # æ‰¾åˆ°æ‰€æœ‰çš„<a>æ ‡ç­¾
        h3_tags = soup.find_all('h2', class_="entry-title")
        for h3_tag in h3_tags:
          # åœ¨æ¯ä¸ª<h3>æ ‡ç­¾ä¸­æ‰¾åˆ°<a>æ ‡ç­¾
          a_tag = h3_tag.find('a')
          # è·å–<a>æ ‡ç­¾çš„hrefå±æ€§å€¼
          if a_tag:
             return a_tag['href'] 
          
  except requests.exceptions.RequestException as e:
      print(f"è¯·æ±‚å‡ºç°é”™è¯¯: {e}")
  current_date = datetime.now()
  formatted_date = current_date.strftime('%Y-%m-%d')
  url = f"https://www.freeclashnode.com/free-node/{formatted_date}-free-subscribe-node.htm"
  return url
def get_indextt_url(url):
  headers = {
      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36',
      'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
      # å…¶ä»–è¯·æ±‚å¤´å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ 
  }

  # å‘èµ· GET è¯·æ±‚
  ymal_urls = []
  try:
      response = requests.get(url, headers=headers, verify=False)  # ç¦ç”¨ SSL éªŒè¯
      #print(f"çŠ¶æ€ç : {response.text}")

      if response.status_code == 200:
        soup = BeautifulSoup(response.text, 'html.parser')
        # æ‰¾åˆ°æ‰€æœ‰çš„<a>æ ‡ç­¾
        h3_tags = soup.find_all('div', class_="col-3")
        for h3_tag in h3_tags:
          # åœ¨æ¯ä¸ª<h3>æ ‡ç­¾ä¸­æ‰¾åˆ°<a>æ ‡ç­¾
          a_tag = h3_tag.find('a')
          # è·å–<a>æ ‡ç­¾çš„hrefå±æ€§å€¼
          if a_tag:
             return a_tag['href'] 
          
  except requests.exceptions.RequestException as e:
      print(f"è¯·æ±‚å‡ºç°é”™è¯¯: {e}")
  current_date = datetime.now()
  formatted_date = current_date.strftime('%Y-%m-%d')
  url = f"https://www.freeclashnode.com/free-node/{formatted_date}-free-subscribe-node.htm"
  return url

def extract_links_url(url):
  # è®¾ç½®è¯·æ±‚å¤´
  headers = {
      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36',
      'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
      # å…¶ä»–è¯·æ±‚å¤´å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ 
  }

  # å‘èµ· GET è¯·æ±‚
  ymal_urls = []
  try:
      response = requests.get(url, headers=headers, verify=False)  # ç¦ç”¨ SSL éªŒè¯
      print(f"çŠ¶æ€ç : {response.status_code}")
      if response.status_code == 200:
        ymal_urls = re.findall(r'https?://[^\s<]+\.yaml', response.text,re.IGNORECASE)
      print(ymal_urls)  # æ‰“å°å“åº”å†…å®¹
  except requests.exceptions.RequestException as e:
      print(f"è¯·æ±‚å‡ºç°é”™è¯¯: {e}")
  return ymal_urls
def extract_yaml_url(url):
  # è®¾ç½®è¯·æ±‚å¤´
  headers = {
      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36',
      'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
      # å…¶ä»–è¯·æ±‚å¤´å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ 
  }
  # å‘èµ· GET è¯·æ±‚
  try:
      response = requests.get(url, headers=headers, verify=False)  # ç¦ç”¨ SSL éªŒè¯
      response.encoding = 'utf-8'
      #print(f"çŠ¶æ€ç : {response.status_code}")
      dct = yaml.safe_load(response.text.replace('ğŸ‘‰','').replace('https://www.fuye.funå…è´¹èŠ‚ç‚¹åˆ†äº«','').replace('()','').replace('( https://www.fuye.fun/å…è´¹èŠ‚ç‚¹åˆ†äº«)',''))
      #print(dct['proxies']) 
      #print(response.text)  # æ‰“å°å“åº”å†…å®¹
  except requests.exceptions.RequestException as e:
      print(f"è¯·æ±‚å‡ºç°é”™è¯¯: {e}")
  return dct['proxies']
def main():
  s=get_index_url("https://www.cfmem.com/")
  print(s)
  url = s
  file1 = open("./sub/proxy_cf.yaml", "w+",encoding='utf-8')
  links = extract_links_url(url)
  print(len(links))
  a=[]
  for link in links:
    s=extract_yaml_url(link)
    a=a+s
  print(a)
  tt=get_indextt_url("https://oneclash.cc/freenode")
  links_tt = extract_links_url(tt)
  b=[]
  for link in links_tt:
    s=extract_yaml_url(link)
    b=b+s
  c =extract_links_url('https://raw.githubusercontent.com/aiboboxx/clashfree/refs/heads/main/clash.yml')
  print(b)
  yaml_content = yaml.dump({"proxies":a+b+c}, default_flow_style=False)
  print(yaml_content)
  file1.write(yaml_content)
  file1.close()
if __name__ == '__main__':
    main()
